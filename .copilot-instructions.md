# GitHub Copilot Instructions

## Project Overview

This is `<module_name>`, a Python template library for miscellaneous operations and tools. The project uses modern Python development practices with uv for dependency management and comprehensive development workflows.

## Project Structure

```
<module_name>/
├── Makefile                 # Development workflow commands
├── pyproject.toml          # Project configuration and dependencies
├── uv.lock                 # Dependency lock file
├── README.md               # Project documentation
├── docs/                   # Documentation and changelogs
│   ├── CHANGELOG.md        # Project changelog
│   └── copilot-changes/    # AI-generated change summaries
├── <module_name>/           # Main package directory
│   ├── __init__.py         # Package initialization
│   ├── __main__.py         # Module execution entry point
│   └── main.py             # Main application logic
└── tests/                  # Test suite
    ├── __init__.py
    └── test_main.py
```

## Technology Stack

- **Python**: 3.14+
- **Dependency Management**: uv (modern, fast alternative to pip)
- **Build System**: hatchling
- **Testing**: pytest with coverage (pytest-cov)
- **Code Quality**: ruff (formatting), ruff (linting), ty (type checking)
- **Pre-commit**: pre-commit hooks for quality gates
- **Task Runner**: Make with comprehensive development targets

## Development Workflow

### Key Make Targets
- `make help` - Show all available commands
- `make dev` - Set up complete development environment
- `make test` - Run tests
- `make all-checks` - Run all quality checks (format, lint, test)
- `make format` - Format code with ruff
- `make lint` - Run ruff linting
- `make run` - Run the application
- `make build` - Build the package
- `make clean` - Clean up artifacts

### Package Execution Methods
1. **Direct import**: `python -c "import <module_name>; <module_name>.main()"`
2. **Module execution**: `python -m <module_name>`

## Coding Standards & Preferences

### Python Style
- **Line length**: 88 characters (ruff default)
- **Target Python version**: 3.14
- **Type hints**: Required for all functions and methods
- **Docstrings**: Use Google style docstrings
- **Import organization**: Follow isort standards, use ruff for formatting
- **Settings management**: Use pydantic for configuration management
- **Configuration files**: Use `pyproject.toml` for project configuration, not `setup.py`. For anything else use toml files.

### Programming Paradigm Preferences
- **Prefer functional programming**: Use simple functions over classes when possible, one function should do one thing. Function names should be descriptive.
- **Module-based organization**: Group related functions in modules rather than classes
- **Immutable data structures**: Prefer immutable types and functional transformations
- **Composition over inheritance**: When classes are needed, favor composition
- **Pure functions**: Minimize side effects, prefer functions that are easy to test

### Code Quality Requirements
- All code must pass ruff formatting
- All code must pass ruff linting
- All new features must include tests
- Maintain >85% test coverage

### Dependency Management
- Use `uv add <package>` to add new dependencies
- Use `uv add --dev <package>` for development dependencies
- Always run `uv lock` after dependency changes
- Use `dependency-groups` in pyproject.toml (not `project.optional-dependencies`)


### Common engineering Patterns
- API integrations should use proper error handling
- Configuration should support multiple environments (dev, staging, prod)
- Logging should be structured and include correlation IDs
- Rate limiting should be considered for API calls
- Authentication tokens should be handled securely

### Naming Conventions
- Use `<module_name>_` prefix for module-specific utilities
- Prefer descriptive function names over class methods
- Module names should be clear and domain-specific
- Use descriptive names that reflect module concepts
- Avoid abbreviations unless they're domain-standard (e.g., `api`, `url`, `id`)

## Testing Guidelines

### Test-Driven Development (TDD)
- **Write tests first**: Always write unit tests before implementing new features
- **Red-Green-Refactor**: Follow TDD cycle - failing test, make it pass, refactor
- **Test coverage**: Ensure new features have comprehensive test coverage before committing

### Test Structure
- Use pytest fixtures for common test setup
- Group related tests in classes when it improves organization
- Use descriptive test method names: `test_<action>_<condition>_<expected_result>`
- Mock external dependencies (APIs, databases, etc.)
- Prefer testing individual functions over complex class hierarchies

### Test Coverage
- Aim for >85% coverage
- Focus on business logic coverage
- Test edge cases and error conditions
- Use parametrized tests for multiple input scenarios

## File Creation Guidelines

### New Python Files
- Always include proper module docstrings
- Add type hints to all functions
- Include `__all__` for public modules
- Follow the existing package structure

### New Test Files
- Name test files as `test_<module_name>.py`
- Include both positive and negative test cases
- Use meaningful assertions with custom messages
- Mock external dependencies appropriately

## Common Patterns to Follow

### Functional Programming Patterns
```python
# Prefer simple functions over classes
def process_shipment_data(data: dict) -> dict:
    """Process shipment data and return normalized result."""
    return {
        'tracking_id': data.get('tracking_number'),
        'status': normalize_status(data.get('status')),
        'updated_at': parse_timestamp(data.get('timestamp'))
    }

# Use pure functions when possible
def calculate_shipping_cost(weight: float, distance: float, rate: float) -> float:
    """Calculate shipping cost based on weight, distance and rate."""
    return round(weight * distance * rate, 2)

# Prefer module-level functions over class methods
def validate_tracking_number(tracking_number: str) -> bool:
    """Validate tracking number format."""
    return len(tracking_number) >= 8 and tracking_number.isalnum()

# For typing certain data structures, or when using complex types
# use typing modules and dataclasses
from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class Shipment:
    tracking_id: str
    status: str
    updated_at: str
    items: List[Dict[str, Any]]  # Example of complex type with typing

```



### Error Handling
```python
import logging
from typing import Optional

logger = logging.getLogger(__name__)

def api_operation() -> Optional[dict]:
    try:
        # API call logic
        return result
    except requests.RequestException as e:
        logger.error(f"API request failed: {e}")
        return None
```

### Configuration Management
```python
from dataclasses import dataclass
from typing import Optional

@dataclass(frozen=True)  # Prefer immutable data structures
class ScloudConfig:
    api_url: str
    api_key: str
    timeout: int = 30
    retries: int = 3


# use pydantic settings for environment-based configurations
from pydantic import BaseSettings

class Settings(BaseSettings):
    api_url: str
    api_key: str
    timeout: int = 30
    retries: int = 3

# Example usage
settings = Settings()
```

### CLI Interface (if needed)
```python
import typer

app = typer.Typer()

@app.command()
def main(env: str = typer.Option("dev", help="Environment to use")) -> None:
    """Main CLI entry point."""
    pass
```

## Development Environment

### Setup Commands
```bash
# Initial setup
make dev

# Daily development
make test          # Run tests
make all-checks    # Full quality check
make format        # Format code
```

### Pre-commit Integration
- Pre-commit hooks are configured for automatic quality checks
- Install with `make pre-commit-install`
- Hooks run: black, flake8, mypy, and basic file checks

## Performance Considerations

- Use async/await for I/O operations when appropriate
- Implement connection pooling for API clients
- Consider caching for frequently accessed data
- Use generators for large data processing
- Profile code for bottlenecks in critical paths

## Security Guidelines

- Never commit secrets or API keys
- Use environment variables for sensitive configuration
- Validate all external inputs
- Use secure HTTP headers for API requests
- Implement proper authentication and authorization

## Documentation

- Update README.md for user-facing changes
- Add docstrings for all public functions/classes
- Include examples in docstrings
- Document any breaking changes in commit messages
- Use conventional commit format: `type(scope): description`

### Change Documentation
- **Copilot Changes**: Document AI-generated changes in `docs/copilot-changes/`
- **Changelog**: Maintain human-readable changelog in `docs/CHANGELOG.md`
- **Commit Process**: Always test changes before committing
- **Change Summaries**: Write clear summaries of what was changed and why

## Deployment & CI/CD

The project is set up for:
- Automated testing on code changes
- Quality gates before merging
- Package building with `uv build`
- Distribution-ready Python packages

When suggesting CI/CD improvements, consider GitLab CI/CD workflows that leverage the existing Makefile targets.

## Development Process

### Feature Development Workflow
1. **Write Tests First**: Create comprehensive unit tests for new functionality
2. **Implement Feature**: Write the minimal code to make tests pass
3. **Refactor**: Clean up code while keeping tests green
4. **Quality Checks**: Run `make all-checks` to ensure code quality
5. **Test Integration**: Verify feature works in the broader system
6. **Documentation**: Update relevant documentation and changelogs
7. **Commit**: Use conventional commit messages with clear descriptions

### Git Branching Workflow

This project follows a **Git Flow** branching strategy:

```
main (master) ←── develop ←── feature/branch-name
     ↓               ↓
   tags/releases   integration
```

#### Branch Structure
- **`main`** (or `master`): Production-ready code, stable releases
- **`develop`**: Integration branch for features, pre-production testing
- **`feature/*`**: Individual feature branches for development

#### Workflow Process
1. **Feature Development**:
   ```bash
   git checkout develop
   git checkout -b feature/feature-name
   # ... develop feature ...
   git push origin feature/feature-name
   ```

2. **Merge Feature to Develop**:
   ```bash
   git checkout develop
   git merge feature/feature-name
   git push origin develop
   git branch -d feature/feature-name  # cleanup
   ```

3. **Release Process (Develop to Main)**:
   ```bash
   git checkout main
   git merge develop
   git push origin main
   ```

4. **Tagging Releases**:
   ```bash
   git tag -a v1.2.0 -m "Release v1.2.0: Description"
   git push origin v1.2.0
   ```

#### Branch Rules
- **Feature branches**: Always branch from and merge back to `develop`
- **Release tags**: Only created on `main` branch
- **Hotfixes**: Can branch from `main`, merge to both `main` and `develop`
- **Direct commits**: Avoid direct commits to `main`, use pull requests when possible

#### Release Strategy
- **Version tags**: Follow semantic versioning (v1.2.3)
- **Tag location**: All release tags are created on `main` branch
- **Release notes**: Update CHANGELOG.md before tagging
- **Testing**: Ensure all tests pass on `develop` before merging to `main`
